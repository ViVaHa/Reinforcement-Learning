{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bnus 2.ipynb","version":"0.3.2","provenance":[{"file_id":"18jm46ZBuLFmb3AbnnpZCEYHlfblMKvUm","timestamp":1544065464334},{"file_id":"1j8LtCXL1E4yae06s2fL0d-rhd4Zpzr0c","timestamp":1544064573703},{"file_id":"1h0NB4Z74d9vSOwzjbHLpwD0oAz2QU7LV","timestamp":1544054959247}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"_TuEZvkGiRbJ","colab_type":"code","outputId":"c284ea92-56f9-4f3c-83b4-6d61ad3a4b45","executionInfo":{"status":"ok","timestamp":1544067016591,"user_tz":300,"elapsed":22392,"user":{"displayName":"Vishnu Varshath Harishankar","photoUrl":"","userId":"00335552339456143148"}},"colab":{"base_uri":"https://localhost:8080/","height":2570}},"cell_type":"code","source":["'''\n","We install the necessary packages required for this Task\n","''' \n","!apt install swig cmake libopenmpi-dev zlib1g-dev\n","!pip install stable-baselines==2.2.0 box2d box2d-kengz\n","!apt-get update &&  apt-get install cmake libopenmpi-dev python3-dev zlib1g-dev\n","!python -m pip install --upgrade pip\n","!pip install -U setuptools\n","!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n","!pip install gym pyvirtualdisplay > /dev/null 2>&1\n","!pip install gym[atari_py]\n","!apt install ffmpeg\n","!which ffmpeg\n","!pip install stable_baselines\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","cmake is already the newest version (3.10.2-1ubuntu2).\n","zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n","libopenmpi-dev is already the newest version (2.1.1-8).\n","swig is already the newest version (3.0.12-1).\n","0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n","Requirement already satisfied: stable-baselines==2.2.0 in /usr/local/lib/python3.6/dist-packages (2.2.0)\n","Requirement already satisfied: box2d in /usr/local/lib/python3.6/dist-packages (2.3.2)\n","Requirement already satisfied: box2d-kengz in /usr/local/lib/python3.6/dist-packages (2.3.3)\n","Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.10.9)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (3.38.0)\n","Requirement already satisfied: zmq in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.0.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (4.28.1)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (3.4.4.19)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (1.14.6)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (7.0)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.6)\n","Requirement already satisfied: mpi4py in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (3.0.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.6.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.2.8.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (1.1.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.13.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.22.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (2.1.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (0.7.1)\n","Requirement already satisfied: tensorflow>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from stable-baselines==2.2.0) (1.12.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (1.3.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (1.11.0)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (2.18.4)\n","Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (0.1.7)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (4.0.0)\n","Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (3.1.0)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->stable-baselines==2.2.0) (2.3.0)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from zmq->stable-baselines==2.2.0) (17.0.0)\n","Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines==2.2.0) (2.5.3)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->stable-baselines==2.2.0) (2018.7)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines==2.2.0) (2.3.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable-baselines==2.2.0) (0.10.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (1.0.6)\n","Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (1.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (0.32.3)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (1.15.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (0.7.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (1.0.5)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (0.6.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable-baselines==2.2.0) (3.6.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (0.16.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (3.0.4)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (1.22)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (2.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (2018.11.29)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari,classic_control]>=0.10.9->stable-baselines==2.2.0) (0.46)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.5.0->stable-baselines==2.2.0) (2.8.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.5.0->stable-baselines==2.2.0) (3.0.1)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.5.0->stable-baselines==2.2.0) (0.14.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.5.0->stable-baselines==2.2.0) (40.6.2)\n","Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  InRelease\n","Ign:2 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  InRelease\n","Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1710/x86_64  Release\n","Hit:4 http://security.ubuntu.com/ubuntu bionic-security InRelease\n","Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1604/x86_64  Release\n","Hit:6 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n","Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Fetched 74.6 kB in 1s (50.1 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","cmake is already the newest version (3.10.2-1ubuntu2).\n","zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n","libopenmpi-dev is already the newest version (2.1.1-8).\n","python3-dev is already the newest version (3.6.7-1~18.04).\n","0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n","Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (18.1)\n","Requirement already up-to-date: setuptools in /usr/local/lib/python3.6/dist-packages (40.6.2)\n","Requirement already satisfied: gym[atari_py] in /usr/local/lib/python3.6/dist-packages (0.10.9)\n","\u001b[33m  gym 0.10.9 does not provide the extra 'atari_py'\u001b[0m\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym[atari_py]) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym[atari_py]) (1.11.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari_py]) (1.3.2)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym[atari_py]) (1.14.6)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari_py]) (2.18.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari_py]) (0.16.0)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari_py]) (2.6)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari_py]) (1.22)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari_py]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari_py]) (2018.11.29)\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","ffmpeg is already the newest version (7:3.4.4-0ubuntu0.18.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n","/usr/bin/ffmpeg\n","Requirement already satisfied: stable_baselines in /usr/local/lib/python3.6/dist-packages (2.2.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.2.8.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (4.28.1)\n","Requirement already satisfied: tensorflow>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (7.0)\n","Requirement already satisfied: zmq in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (1.14.6)\n","Requirement already satisfied: gym[atari,classic_control]>=0.10.9 in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.10.9)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.13.0)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.7.1)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.6)\n","Requirement already satisfied: mpi4py in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (3.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.22.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (0.6.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (2.1.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (1.1.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (3.4.4.19)\n","Requirement already satisfied: progressbar2 in /usr/local/lib/python3.6/dist-packages (from stable_baselines) (3.38.0)\n","Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (0.6.1)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (0.7.1)\n","Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (0.2.0)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (1.0.5)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (1.1.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (3.6.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (1.15.0)\n","Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (1.0.6)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (1.11.0)\n","Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (1.12.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=1.5.0->stable_baselines) (0.32.3)\n","Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from zmq->stable_baselines) (17.0.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable_baselines) (1.3.2)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable_baselines) (2.18.4)\n","Requirement already satisfied: Pillow; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable_baselines) (4.0.0)\n","Requirement already satisfied: PyOpenGL; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable_baselines) (3.1.0)\n","Requirement already satisfied: atari-py>=0.1.4; extra == \"atari\" in /usr/local/lib/python3.6/dist-packages (from gym[atari,classic_control]>=0.10.9->stable_baselines) (0.1.7)\n","Requirement already satisfied: python-dateutil>=2 in /usr/local/lib/python3.6/dist-packages (from pandas->stable_baselines) (2.5.3)\n","Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas->stable_baselines) (2018.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable_baselines) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->stable_baselines) (2.3.0)\n","Requirement already satisfied: python-utils>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from progressbar2->stable_baselines) (2.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow>=1.5.0->stable_baselines) (40.6.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow>=1.5.0->stable_baselines) (2.8.0)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.5.0->stable_baselines) (0.14.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow>=1.5.0->stable_baselines) (3.0.1)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym[atari,classic_control]>=0.10.9->stable_baselines) (0.16.0)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable_baselines) (3.0.4)\n","Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable_baselines) (1.22)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable_baselines) (2018.11.29)\n","Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0->gym[atari,classic_control]>=0.10.9->stable_baselines) (2.6)\n","Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow; extra == \"atari\"->gym[atari,classic_control]>=0.10.9->stable_baselines) (0.46)\n"],"name":"stdout"}]},{"metadata":{"id":"bJNRHCVViasH","colab_type":"code","colab":{}},"cell_type":"code","source":["'''\n","This block contains all the necessary imports required for this task\n","'''\n","import os\n","import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from stable_baselines.bench import Monitor\n","from stable_baselines.results_plotter import load_results, ts2xy\n","from stable_baselines import DQN\n","from stable_baselines.deepq.policies import MlpPolicy\n","from stable_baselines.ddpg.noise import AdaptiveParamNoiseSpec\n","from stable_baselines.common.vec_env import DummyVecEnv\n","from stable_baselines.deepq.build_graph import build_act, build_train\n","import gym\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from IPython import display as ipythondisplay\n","import random, math, time\n","import numpy as np\n","from pyvirtualdisplay import Display\n","\n","from matplotlib.image import imread\n","from matplotlib import rc, animation\n","from IPython import display\n","from IPython.display import HTML\n","%matplotlib inline\n","\n","try:\n","  from google.colab import files\n","except:\n","  print(\"Could not import Google Colab.\")\n","\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DlDBUgnZfY0L","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","display = Display(visible=0, size=(400, 300))\n","display.start()\n","best_mean_reward, n_steps = -np.inf, 0\n","plt.rcParams['animation.ffmpeg_path'] = u'/usr/bin/ffmpeg'"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NFsDt0AdiglU","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\"\"\"\n","Callback called at each step for our DQN algorithm\n","\"\"\"\n","def callback(_locals, _globals):\n","  global n_steps, best_mean_reward\n","  # Print stats for every 1000 calls made\n","  if (n_steps + 1) % 1000 == 0:\n","      # Evaluate policy performance\n","      x, y = ts2xy(load_results(log_dir), 'timesteps')\n","      if len(x) > 0:\n","          mean_reward = np.mean(y[-100:])\n","          print(x[-1], 'timesteps')\n","          print(\"Best mean reward: {:.2f} - Last mean reward per episode: {:.2f}\".format(best_mean_reward, mean_reward))\n","\n","          # New best model, you could save the agent here\n","          if mean_reward > best_mean_reward:\n","              best_mean_reward = mean_reward\n","              # Example for saving best model\n","              print(\"Saving new best model\")\n","              _locals['self'].save(log_dir + 'best_model.pkl')\n","  n_steps += 1\n","  return True"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rw97XYYBUpn0","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create log dir\n","log_dir = \"/tmp/gym/\"\n","os.makedirs(log_dir, exist_ok=True)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vfsgGHnmi35l","colab_type":"code","outputId":"0acde083-d0c8-47f3-fef4-1a29dfd21f1c","executionInfo":{"status":"ok","timestamp":1544067026999,"user_tz":300,"elapsed":32762,"user":{"displayName":"Vishnu Varshath Harishankar","photoUrl":"","userId":"00335552339456143148"}},"colab":{"base_uri":"https://localhost:8080/","height":71}},"cell_type":"code","source":["'''\n","The attari environment that was chosen Demon Attack. \n","The goal of the game is to maximize the points by killing all the demons while surviving the attack from demons.\n","'''\n","env = gym.make('DemonAttack-ram-v0')\n","'''\n","Monitor as the name suggests monitors training and logs all in the information in log_dir/monitor.csv\n","'''\n","env = Monitor(env, log_dir, allow_early_resets=True)\n","\n","#VecEnv runs multiple environments sequentially\n","env = DummyVecEnv([lambda: env])\n","\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n","  result = entry_point.load(False)\n"],"name":"stderr"}]},{"metadata":{"id":"9rGMqLf_iO-a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":3723},"outputId":"509dabc2-e2d2-422d-d8ca-2e98964f111c","executionInfo":{"status":"ok","timestamp":1544067354953,"user_tz":300,"elapsed":360715,"user":{"displayName":"Vishnu Varshath Harishankar","photoUrl":"","userId":"00335552339456143148"}}},"cell_type":"code","source":["'''\n","Defines the DQN algorithm which we will be using \n","'''\n","model = DQN(MlpPolicy, env, verbose=1)\n","\n","'''\n","model.learn returns a trained model in order for us to predict later\n","total_timesteps->The total number of samples to train on\n","'''\n","model.learn(total_timesteps=100000, callback=callback)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2900 timesteps\n","Best mean reward: -inf - Last mean reward per episode: 100.00\n","Saving new best model\n","2900 timesteps\n","Best mean reward: 100.00 - Last mean reward per episode: 100.00\n","4292 timesteps\n","Best mean reward: 100.00 - Last mean reward per episode: 100.00\n","5587 timesteps\n","Best mean reward: 100.00 - Last mean reward per episode: 118.75\n","Saving new best model\n","6567 timesteps\n","Best mean reward: 118.75 - Last mean reward per episode: 117.00\n","7481 timesteps\n","Best mean reward: 118.75 - Last mean reward per episode: 114.17\n","8509 timesteps\n","Best mean reward: 118.75 - Last mean reward per episode: 116.43\n","9847 timesteps\n","Best mean reward: 118.75 - Last mean reward per episode: 118.12\n","9847 timesteps\n","Best mean reward: 118.75 - Last mean reward per episode: 118.12\n","11326 timesteps\n","Best mean reward: 118.75 - Last mean reward per episode: 120.56\n","Saving new best model\n","11326 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 120.56\n","13330 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 118.50\n","13330 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 118.50\n","15361 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 120.45\n","16539 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 106.54\n","17245 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.64\n","17245 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.64\n","19222 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.33\n","20905 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 100.83\n","21779 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 100.79\n","21779 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 100.79\n","21779 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 100.79\n","24179 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.50\n","24179 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.50\n","24179 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.50\n","24179 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.50\n","24179 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 104.50\n","29878 timesteps\n","Best mean reward: 120.56 - Last mean reward per episode: 121.43\n","Saving new best model\n","29878 timesteps\n","Best mean reward: 121.43 - Last mean reward per episode: 121.43\n","29878 timesteps\n","Best mean reward: 121.43 - Last mean reward per episode: 121.43\n","32394 timesteps\n","Best mean reward: 121.43 - Last mean reward per episode: 128.64\n","Saving new best model\n","32394 timesteps\n","Best mean reward: 128.64 - Last mean reward per episode: 128.64\n","32394 timesteps\n","Best mean reward: 128.64 - Last mean reward per episode: 128.64\n","35817 timesteps\n","Best mean reward: 128.64 - Last mean reward per episode: 139.13\n","Saving new best model\n","35817 timesteps\n","Best mean reward: 139.13 - Last mean reward per episode: 139.13\n","35817 timesteps\n","Best mean reward: 139.13 - Last mean reward per episode: 139.13\n","35817 timesteps\n","Best mean reward: 139.13 - Last mean reward per episode: 139.13\n","39685 timesteps\n","Best mean reward: 139.13 - Last mean reward per episode: 158.33\n","Saving new best model\n","39685 timesteps\n","Best mean reward: 158.33 - Last mean reward per episode: 158.33\n","39685 timesteps\n","Best mean reward: 158.33 - Last mean reward per episode: 158.33\n","42009 timesteps\n","Best mean reward: 158.33 - Last mean reward per episode: 160.20\n","Saving new best model\n","42009 timesteps\n","Best mean reward: 160.20 - Last mean reward per episode: 160.20\n","44590 timesteps\n","Best mean reward: 160.20 - Last mean reward per episode: 165.38\n","Saving new best model\n","44590 timesteps\n","Best mean reward: 165.38 - Last mean reward per episode: 165.38\n","44590 timesteps\n","Best mean reward: 165.38 - Last mean reward per episode: 165.38\n","44590 timesteps\n","Best mean reward: 165.38 - Last mean reward per episode: 165.38\n","44590 timesteps\n","Best mean reward: 165.38 - Last mean reward per episode: 165.38\n","44590 timesteps\n","Best mean reward: 165.38 - Last mean reward per episode: 165.38\n","44590 timesteps\n","Best mean reward: 165.38 - Last mean reward per episode: 165.38\n","51013 timesteps\n","Best mean reward: 165.38 - Last mean reward per episode: 196.30\n","Saving new best model\n","51013 timesteps\n","Best mean reward: 196.30 - Last mean reward per episode: 196.30\n","53503 timesteps\n","Best mean reward: 196.30 - Last mean reward per episode: 200.89\n","Saving new best model\n","53503 timesteps\n","Best mean reward: 200.89 - Last mean reward per episode: 200.89\n","55969 timesteps\n","Best mean reward: 200.89 - Last mean reward per episode: 203.10\n","Saving new best model\n","55969 timesteps\n","Best mean reward: 203.10 - Last mean reward per episode: 203.10\n","55969 timesteps\n","Best mean reward: 203.10 - Last mean reward per episode: 203.10\n","58254 timesteps\n","Best mean reward: 203.10 - Last mean reward per episode: 207.67\n","Saving new best model\n","58254 timesteps\n","Best mean reward: 207.67 - Last mean reward per episode: 207.67\n","58254 timesteps\n","Best mean reward: 207.67 - Last mean reward per episode: 207.67\n","61530 timesteps\n","Best mean reward: 207.67 - Last mean reward per episode: 208.55\n","Saving new best model\n","62455 timesteps\n","Best mean reward: 208.55 - Last mean reward per episode: 205.78\n","62455 timesteps\n","Best mean reward: 208.55 - Last mean reward per episode: 205.78\n","62455 timesteps\n","Best mean reward: 208.55 - Last mean reward per episode: 205.78\n","65983 timesteps\n","Best mean reward: 208.55 - Last mean reward per episode: 232.27\n","Saving new best model\n","65983 timesteps\n","Best mean reward: 232.27 - Last mean reward per episode: 232.27\n","65983 timesteps\n","Best mean reward: 232.27 - Last mean reward per episode: 232.27\n","65983 timesteps\n","Best mean reward: 232.27 - Last mean reward per episode: 232.27\n","69617 timesteps\n","Best mean reward: 232.27 - Last mean reward per episode: 236.76\n","Saving new best model\n","69617 timesteps\n","Best mean reward: 236.76 - Last mean reward per episode: 236.76\n","69617 timesteps\n","Best mean reward: 236.76 - Last mean reward per episode: 236.76\n","72580 timesteps\n","Best mean reward: 236.76 - Last mean reward per episode: 239.29\n","Saving new best model\n","72580 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 239.29\n","74566 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 237.08\n","74566 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 237.08\n","76285 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 230.00\n","77714 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 227.18\n","77714 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 227.18\n","79387 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 228.12\n","80983 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 228.29\n","80983 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 228.29\n","82806 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 228.81\n","82806 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 228.81\n","82806 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 228.81\n","82806 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 228.81\n","86913 timesteps\n","Best mean reward: 239.29 - Last mean reward per episode: 251.86\n","Saving new best model\n","86913 timesteps\n","Best mean reward: 251.86 - Last mean reward per episode: 251.86\n","86913 timesteps\n","Best mean reward: 251.86 - Last mean reward per episode: 251.86\n","86913 timesteps\n","Best mean reward: 251.86 - Last mean reward per episode: 251.86\n","90313 timesteps\n","Best mean reward: 251.86 - Last mean reward per episode: 275.23\n","Saving new best model\n","90313 timesteps\n","Best mean reward: 275.23 - Last mean reward per episode: 275.23\n","90313 timesteps\n","Best mean reward: 275.23 - Last mean reward per episode: 275.23\n","93914 timesteps\n","Best mean reward: 275.23 - Last mean reward per episode: 278.44\n","Saving new best model\n","93914 timesteps\n","Best mean reward: 278.44 - Last mean reward per episode: 278.44\n","95662 timesteps\n","Best mean reward: 278.44 - Last mean reward per episode: 278.80\n","Saving new best model\n","96601 timesteps\n","Best mean reward: 278.80 - Last mean reward per episode: 274.36\n","96601 timesteps\n","Best mean reward: 278.80 - Last mean reward per episode: 274.36\n","96601 timesteps\n","Best mean reward: 278.80 - Last mean reward per episode: 274.36\n","99051 timesteps\n","Best mean reward: 278.80 - Last mean reward per episode: 276.04\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<stable_baselines.deepq.dqn.DQN at 0x7f785afeeb00>"]},"metadata":{"tags":[]},"execution_count":7}]},{"metadata":{"id":"0h9IvCsoiW8u","colab_type":"code","colab":{}},"cell_type":"code","source":["def movingAverage(values, window):\n","    \"\"\"\n","    Smooth values by doing a moving average\n","    \"\"\"\n","    weights = np.repeat(1.0, window) / window\n","    return np.convolve(values, weights, 'valid')\n","\n","\n","def plot_results(log_folder, title='Learning Curve'):\n","    \"\"\"\n","    plots the results in using matplotlib\n","    \"\"\"\n","    x, y = ts2xy(load_results(log_folder), 'timesteps')\n","    y = movingAverage(y, window=50)\n","    # Truncate x\n","    x = x[len(x) - len(y):]\n","\n","    fig = plt.figure(title)\n","    plt.plot(x, y)\n","    plt.xlabel('Number of Timesteps')\n","    plt.ylabel('Rewards')\n","    plt.title(title + \" Smoothed\")\n","    plt.show()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_i4-qgIYigzL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":294},"outputId":"7065ab4b-4dc3-4bdb-cc8d-d4bc9df8f7c4","executionInfo":{"status":"ok","timestamp":1544067355093,"user_tz":300,"elapsed":360853,"user":{"displayName":"Vishnu Varshath Harishankar","photoUrl":"","userId":"00335552339456143148"}}},"cell_type":"code","source":["plot_results(log_dir)"],"execution_count":9,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYMAAAEVCAYAAAACW4lMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAHS1JREFUeJzt3X28ZXPd//HXMeMmTGNwJJUk9aGU\nSngMMzFxucndpYhSIqX4qdTVDVHxUykT3SpNbq+oSFfXj5Byl3tDUSo+SlcK4TBjjJuLjPP74/s9\n2XOcc2YPZ+2zz3g9H495nL3XXnutz15zznqv9f2u/V09/f39SJKe25Ya6wIkSWPPMJAkGQaSJMNA\nkoRhIEnCMJAkARPHugCNXxHRD7wkM+/o8Hp3AXbMzPeO4jK3Az4LrAwsDdwEHJyZN4/WOhajlg8D\n7691LANcDhyYmfMbXu+ywO6Z+Z/1+bP+/42IC4HTMvOU0alSTfHMQONOZv50lINge+Ak4OOZGcDL\ngXOByyNitdFaT5u1bAvsD8zIzHWB9YDnATM7sPrXA3t1YD3qQp4ZaNTVI8yZwLaUI9tZmfnF+tpU\n4FvACsCTwIcz88KIWAu4CjgDeENmbl6PTPcCPgasDhydmV+NiL2Bd2XmVhFxCnA7sCnwSuBWYOfM\nfCQitgFOAB4Cvgp8BXhtZv51UMmHA5/LzCsBMrMfmBURdwKPtq6vfobB658DbAX8BPgIsFpmPlHn\n/W/g58DJw22TQV4D/Dkz76u1PBYR7wP66/JOAe6sn3d94HvAX+p6JwG7ZeZ1EbEycDywAbAAODUz\nv1yXsQVwLLA8MA/4P8DfgZ8Cz4+IyzNzeq3nLRHxAeCFwDGZeUxdxn71/2U54GrgvZn5aESsDfwQ\nWBW4Bvcx44ZnBmrCJ4FXUXZsrwZ2jYgd6muzgJn1qPdLlB3WgFWBGzNz85Zpr87M1wM7AV+MiAlD\nrG83YHfKEX0vsEud71Rgv8xcD3gFJYAWEhErABtSzgQWkpnnttk0syWwcWYeAdwNTK/LXh54MyUk\nRtomrS4Eto6IUyNiu4iYlJkPDqpjO2AHYEZdbm9mvgY4C/hwneeLwNx6pjMNOCAipkXEisCPgQ/V\n/4OjgR8AfcAhwNUtQQCwVmZuSNn+n4+IpSNiOnAk8ObMXIsSKEfW+b8EXJSZLwe+DmzWxvZTFzAM\n1IQdgW9n5mOZ+TDwn8Bb62uvA86sjy8H1m5539KUo9NW368/f0M5Ch2q2ebczJxTj8ZvAtaknCUs\nm5nn13m+ydC/71OAHuCeNj/bUC7KzP+tj8+i7DihnAXMzsw+Rt4m/5KZN1B2oEtRwuz+iPhpRKzZ\nMtsv6zL+UOc7p06/CVijPt4e+HZd5hzgv4CtgU2AO1rOgn5CCeG1hvlsp9WfN1C2/6r1s5yRmXfV\n145v+SxvopzdkZmzgVuGWa66jGGgJqwEfDUibomIWyhNGANH5XsCsyMigV9SdsQDFmTmg4OWNQ8g\nMxfU50OdGcxrXUadZwowt2X6XQxtDqW56kUjfqKRzWl53BoG/07dMTLyNllIZl6fme8GXgBMBZZt\nWQ7A/Dpff639oTp94LNDOUNq/fxzKUE6eDrAAwwdsgAP1nW1bv+VgHe0fJYzKU1fUDrgW/8/Bq9L\nXcr2PDXhLuArmfmz1okR8SJKG/cmmXljRLyC0sbfhAeBFVuerz7UTLVvYTbwNko7emu9HwXOZuGd\nLJSgGVJm/i4iFkTEBsA2wEfrS0Nuk8EiYhrwP5l5Z93Z/zoiPkVpl18c9wCrAH+rz1ep0wamD6yv\nh7IDvwdYt81l30Xpg/j4EK/NBSa3PO9dvLI1VjwzUBP+H/C+iJgQET0RcVi9SqYXeBi4JSImAvsB\n1Hbs0fYnYOnaWQrwQWon7BA+Axxaa6TWvD9wEOWo+R9lcixX+wF2XcS6z6J0St+YmffXacNtk8H2\nBL4TEc+vtUwE3gH8apGfeGE/46ntuyqlGedcYDaweu3IB9gDuAP4K/BPSgdyz9OWtrCzgbdGRG9d\n/s41sKCE1i51+qbAOotZt8aIYaBn69KB5oL6bxpwHOUKnz9Q2ozXA64AfgucRzkbuJrS1n0Ni7+j\nW6TMfIxyieYpEXFjXeeTDBEImXkhZaf4uYj4M3AzpRN4et2ZXwJcW5dxPmXHPpKzKE1EZ7ZMG26b\nDHZQXc91tSntVkpz0T6L/tQLOQyYUptxLgO+lJmza1/D24Fv1dcOAPaoZyFXUPoc7hqmox6AzPwN\npYP60oi4mXJV0cA2+SSwY0TcBhxIaQrUONDj/Qz0XFCvGnoIWCkz5y1qfum5xjMDLbEi4rqI2L0+\n3R242SCQhmYHspZkHwWOi4gjKR3K7xnjeqSuZTORJMlmIknSOG0m6uub3z9lyvLMnfvIWJeyWKy5\neeOtXrDmTrFm6O2dNOxlw+P2zGDixGGvfOta1ty88VYvWHOnWPPIxm0YSJJGj2EgSTIMJEmGgSQJ\nw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJ\nEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSBExscuERcTQwva7nKOAdQG99\neWXgGuCLwE3Ar+v0vszcrcm6JEkLaywMImIGsH5mTo2IVYAbMnPNltdPAk6oTzMzt2iqFknSyJps\nJroMGDjCfwBYISImAEREACtl5uwG1y9JalNPf39/4yuJiP2A6Zn57vr828CPM/OSiFgLuILSZLQG\ncFxmnj7S8p54YkH/xIkTGq5akpY4PcO90GifAUBE7AzsC2xdny8DTMvMA+os9wOfAU4DJgOzI+Li\nzPzHcMucO/cRensn0dc3v9niR5k1N2+81QvW3CnWXJY3nKY7kLcBDgW2zcx5dfLmwL+ahzJzPnBy\nfXpfRFwPrAsMGwaSpNHVWJ9BREwGZgI7ZOaclpc2An7bMt+MiDi2Pl4BeB1wa1N1SZKerskzg92B\nVYEzS38xAHsBLwRua5nvcuA9EXE1MAE4KjPvbLAuSdIgjYVBZs4CZg3x0ocGzfcEsHdTdUiSFs1v\nIEuSDANJkmEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIk\nDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSgIlN\nLjwijgam1/UcBbwD6K0vrwxck5n7RcQngN2AfuCIzDyvybokSQtrLAwiYgawfmZOjYhVgBsyc82W\n108CToiIlwF7AFOBycDlEXFBZi5oqjZJ0sKabCa6jHK0D/AAsEJETACIiABWyszZwAzg/Mx8PDP7\ngNuBVzVYlyRpkMbODOqR/cP16b7AeS1H+x8Bvlkfrw70tbz1XuCFwE3DLXvKlOUB6O2dNIoVd4Y1\nN2+81QvW3CnWPLxG+wwAImJnShhsXZ8vA0zLzAOGeUvPopY5d+4j9PZOoq9v/ugV2gHW3LzxVi9Y\nc6dY88jB0ujVRBGxDXAosF1mzquTNwdmt8x2F+XsYMCL6jRJUoc0FgYRMRmYCeyQmXNaXtoI+G3L\n84uB7SNimYhYgxIGf2yqLknS0zXZTLQ7sCpwZukvBmAvSn/AbQMTMvNvEfE9SodzP7B/Zj7ZYF2S\npEGa7ECeBcwa4qUPDTHvN3mqQ1mS1GF+A1mSZBhIkgwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwk\nSRgGkiQMA0kShoEkiWcYBhFhiEjSEqStUUsjYm9gecoopJcCL4mIL2Xmd5orTZLUKe0e4X8AOAH4\nd+D3wMso9yuQJC0B2g2DRzPzceAtwJn15jP9zZUlSeqkttv+I+I4YDPgVxExFViusaokSR3Vbhjs\nCfwJ2CkzFwBrAR9sqihJUmeN2IEcEW9qefob4AUR8QLgTmByk4VJkjpnUVcTfaH+XBZ4DXALMAEI\n4FrgTcO8T5I0jozYTJSZ0zNzOnAz8LLMfH1mvhZYB/hLJwqUJDWv3T6DdTLz7oEnmfl3yuWlkqQl\nQFtfOgPui4gfAlcATwJTgUcaq0qS1FHthsEewLso/QY9wNXA95sqSpLUWe2GwUcy80uNViJJGjPt\n9hmsHxHrNFqJJGnMtHtm8FrgjxExB3ic0lTUn5lrNlaZJKlj2g2DHYeYNmU0C5EkjZ22wiAzb4+I\nVwGr1knLAt8A1hvpfRFxNDC9ruco4BzgVMr3FOYDu2bm3Ij4J3Bly1u3rMNeSJI6oN37GXwd2BpY\nHfgz8HLgK4t4zwxg/cycGhGrADfU9/dl5jsjYj9KUJwNzMvMLZ7xp5AkPSvtNhNtnJnrRcQlmTkj\nIjYEdlnEey4DZtfHDwArUJqbPgeQmbOeScHPxpkX/5nrbrm306v9lwkTeliwYHyN/D3eah5v9YI1\nd8qSUvNG667G2988+tfztBsGj9Wfy0ZET2b+OiJGPDOozTwP16f7AucBbwS2q81HdwMHZOYcYLmI\n+AHwUuAnmXnsSMueMmV5AHp7J7VZfvG85ZdhwoSexXrPaBvr9T8T463m8VYvWHOnLAk1P2/5ZRZ7\n39eOnv7+RSdlRHwX+C2wJmWHnsCmmfn6Nt67M/BpSjPTtcDhmfmjiDgMmJyZn4iIDwKnUW6Ycxnw\ngcy8frhl9vXN7+/tnURf3/xF1t5NrLl5461esOZOsWbo7Z00bBq29T2DzPwA8EPKTv0kSr/BUFcY\nLSQitgEOBbbLzHnAPcCv6ssXAK+uyz8+Mx/KzIeBiyjfdJYkdUi7Hcg3AT8HfkFpxnlsEW8hIiYD\nM4GtalMQwPnAtsDJwIZARkRQ+hH2pAyPvRlw1mJ+DknSs9Bun8FWwAxgV2BmRPwDuCAzvzbCe3an\nXIp6ZtnfA7AXcExE7As8BLwnM++JiL9TOpufBM7OzNlDLVCS1Ix2v2dwD/CjiLgC2Jyyo/80MGwY\n1KuFhrpiaLch5v1UW9VKkhrRbjPRicDalCuALgcOzcybmixMktQ57Q5UtyJlPKJ5wBygr7GKJEkd\n1+7VRLvXbwgfB/QCJ0fEzU0WJknqnHabiZ4PTKP0F2xGCZGfNliXJKmD2r2a6EbgQuCXwJdbLhWV\nJC0B2m0mWpsyoNwLMnNORLw8Isbf97olSUNqKwwi4svAe4F96qR3UoawliQtAdq9mmjzzHwr8CBA\nZh4JvKGxqiRJHdVuGDxaf/YDRMQE2u9vkCR1uXbD4KqIOAVYIyI+RhlZ9NKmipIkdVa7R/fHUsYm\nehh4MXAM5c5lkqQlwIhhEBHTgR8By1G+dbxDZv45Ig6kdCC/uPkSJUlNW9SZwRcoQ1DfHBE7Ad+N\niKWAucDGjVcnSeqIRfUZLMjMmwEy82xgLeAbmfnWzLyr6eIkSZ2xqDAYfE/Mv2Wmw1BI0hKm3auJ\nBiz6hsmSpHFnUX0Gm0bE31qer1af9wD9mblmc6VJkjplUWEQi3hdkrQEGDEMMvP2ThUiSRo7i9tn\nIElaAhkGkiTDQJJkGEiSMAwkSRgGkiQMA0kShoEkCcNAkkTD9zGOiKOB6XU9RwHnAKcC6wDzgV0z\nc25E7AkcBDwJzMrME5usS5K0sMbODCJiBrB+Zk4FtgW+Brwf6MvMjYEzgOkRsQLwWWArYAvgoxGx\nclN1SZKerslmosuA3erjB4AVgB2B0wEyc1a9Yc4mwHWZOS8zHwWuBDZrsC5J0iCNNRNl5gLg4fp0\nX+A84I3AdrX56G7gAGB1yv2VB9wLvHCkZU+ZsjwAvb2TRrfoDrDm5o23esGaO8Wah9donwFAROxM\nCYOtgWuBzMwjIuIw4BDghkFv6VnUMufOfYTe3kn09c0f9XqbZM3NG2/1gjV3ijWPHCyNXk0UEdsA\nhwLbZeY84B7gV/XlC4BXA3dRzg4GvKhOkyR1SJMdyJOBmcAOmTmnTj6f0pkMsCGQlLOFjSJipYhY\nkdJfcHlTdUmSnq7JZqLdgVWBMyP+dcO0vYBjImJf4CHgPZn5aEQcTDlT6AeOqGcRkqQOabIDeRYw\na4iXdhti3rOAs5qqRZI0Mr+BLEkyDCRJhoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaB\nJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQM\nA0kShoEkCcNAkoRhIEkCJja58Ig4Gphe13MUsBOwIXB/nWVmZp4bEf8Ermx565aZuaDJ2iRJT2ks\nDCJiBrB+Zk6NiFWAG4CLgUMy82eDZp+XmVs0VYskaWRNnhlcBsyujx8AVgAmNLg+SdIz1NPf39/4\nSiJiP0pz0QJgdWAZ4F7gwMy8LyIeAs4GXgr8JDOPHWl5TzyxoH/iRHNFkhZTz3AvNNpnABAROwP7\nAlsDbwTuz8wbI+Jg4HDgQODjwGlAP3BZRFyWmdcPt8y5cx+ht3cSfX3zmy5/VFlz88ZbvWDNnWLN\nZXnDaboDeRvgUGDbzJwHXNTy8tnAdwAy8/iW91wEvAYYNgwkSaOryQ7kycBMYKvMnFOn/QT4RGb+\nBdgC+H1EBPA5YE9Kn8JmwFlN1SVJeromzwx2B1YFziz7ewBOBs6IiEeAh4B9MvPeiPg7pbP5SeDs\nzJw91AIlSc1oLAwycxYwa4iXTh1i3k81VYckadH8BrIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnC\nMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CS\nhGEgScIwkCRhGEiSMAwkSRgGkiQMA0kS0NPf3z/WNUiSxphnBpIkw0CSZBhIkjAMJEkYBpIkDANJ\nEoaBJAmYONYFRMRSwPHA+sDjwAeBg4ENgfvrbDMz89yI+CdwZcvbt6QE2inAS4EFwD6Z+ZeI2AD4\nDtAP/C4z92+45tuAU4F1gPnArpk5NyL2BA4CngRmZeaJEbF0l9fczdv5SKC3zrIycE1m7hcRnwB2\nq3UckZnnRcRk4AfAZOAh4J2ZOScitgK+WD/HeZl5ZKdrruu/Cfh1nd6Xmbt1Uc2r1fX9E3gYeHf9\n3ejm7fy0mmtN3bydAWZRtuetwP6Z+cRY7De64cxgZ2ByZm4K7At8pU4/JDO3qP/OrdPmtUzbIjMX\nAO8EHsjMacAXgKPqvF8DPpKZmwGTI2K7hmt+P+UXbWPgDGB6RKwAfBbYCtgC+GhErNzNNdd5u3Y7\nZ+ZuA3UB1wMnRMTLgD2AacAOwLERMYHyx3Rprfm/gE/V5X4DeBuwGbB1RLyq0zXXebNlG+9Wp3VF\nzcCxwL6ZOQO4CvhAt2/noWqu83bzdv4ycFRmbg78DXj7WO03uiEMXgHMBsjM2yipN2Ex3r8l8NP6\n+EJgs4hYBnhZZl5Xp59D2bCjZaiadwROr9NmZebZwCbAdZk5LzMfpRxtb9blNQ+nK2quOx8iIoCV\nMnM2MAM4PzMfz8w+4HbgVYNqPgfYKiLWBuZk5t8z80ngvDpfp2seTlfUDMwFVqmvTwHuo8u38zA1\nD6dban7lwDTgAmBrxmi/0Q1hcBOwTURMqH8sawOrAgdGxMUR8aOIWLXOu1xE/CAiroyIj9VpqwN9\nAPU/sL9Om9uyjnuBFzZc81rAdhFxaa155dbaBtXRzTVDd2/ngd+FjwDfHFzboDpapw81bSxrBlg9\nIs6KiKtqs8DgzzKWNX8e+O+ISMoZ4ykj1NHNNUN3b+e7ge3r69sALxihjkb/Bsc8DDLzfEoyXkY5\ndbsZOA04ODPfDNwIHF5n/ziwHyU994yINw6xyJ42p412zT3U01Hg98Ahi1FHt9Xc1du5Hg1Ny8xL\nhnnr4tQ2VjXfD3wGeAewE3BkRAz+Ix7Lmj8D7JKZAVwBHNBmHd1Wc7dv570oTUMXU/bHz3abPuOa\nx7wDGSAzDxt4HBG3AT+syQdwNqVzhMw8vmW+i4DXAHdR0vG3tYOlB/gHT50uAryoztdkzXcBv6qT\nLgCOAM6ttbXWcU2X19zt2/leyulya1PLXUAMUcdAzfOGmDamNWfmfODk+vS+iLgeWLeLal4zMwcu\nIvglsCdwMd29nZ9Wc2Z+g+7ezndm5g71+TaUo/qh6mh8vzHmZwYRsUFEnFQfbwv8Bvhxbb+D0oHy\n+yh+EBE9ETGR0ob2B+AXlKsboLSBX5KZ/wRuiYhpdfpbgZ83XPO5wLZ1lg2BBK4FNoqIlSJixVrz\n5d1cc7dv53qQsBHw25ZZLwa2j4hlImINyh/EHwfV/Dbg55n5V+D5EbFW/Xw71Pk6WnNEzIiIY+vj\nFYDXUa4m6Yqagbvjqc7TjYA/0eXbeaiax8F2/lxEDDQT7UNp8x+T/UY3nBncBCwVEbOB/6UcgawD\nnBERj1Au+9onM++NiL9Tjq6eBM7OzNkR8Wvg3yLiCuAxYO+63IOA70a5nOvazLyw4ZrvB06NiH1r\nze/JzEcj4mDKUffApXjzIuKMLq75ni7fzlCOnm4bmCkz/xYR36OcfvdTLs97MiK+AZwWEZcDDwDv\nqm/ZH/hhfXxGZt7a6Zopf9zviYirKRdMHJWZd3ZRzS8BvhflMuM5wHsz84Eu385Pq5n6e93F23l5\n4PsRcThwedYrJ8div+H9DCRJY99MJEkae4aBJMkwkCQZBpIkDANJEt1xaamewyJiLeB/gHdl5ukt\n0/+amWuNwvL7gaUz84lnu6wR1vE2YCbwhcw8sU57FfDtOsu6lC83/QNYkJlbRsSlwJZZBgEc7XrW\nANbNzItHe9lachkG6ga3Ur58c3b9Zu548xbKMOsnDkzIzD9SvjBJRJwCXJGZJ7S8vkWD9cwA1qN8\nSUxqi2GgbvAPyhdsPgN8svWFiNgb2Coz31WfX0oZkOwJ4FDgDsq3Ta8BfgfsQhkYbrvMvKMu5tMR\nsSUwCdgrM38fEa8FjgGWrv8OzMwb6vJvBF4PvLn1yL1+U/SzwCP1337AVMpAY9MiYkFmzmrnAw+c\nsQCHUYYYWB3YgDKk8euAN9btslNm9kfEh4C3U/5mb6GMuzOBMib/lLqsc+rzL1DGQ5oDfAs4jvJF\nzkmUoV6Oqdt1F8qXml5Ul/leyn0XTqcMdfA84LuZeVI7n0njm30G6hbHUoY6iEXO+ZSNgf+g7Dj3\npIz1PoNyI5NdW+a7Oct48cfx1KCHpwMfrEfoB/DUPQYAHsrMzQcFwfJ1nrfVdZwPfD4zz6J8/X9m\nu0EwhPUoO+Z9KKOazqQE3PrABhGxcX39TZk5lfKN2fcB/0ZpApsObEr5tu3tlNE6v5+Zx1JGSr2r\n1rwJsEcNQijbb8/686XAdsDuwC11u2xO+YasngMMA3WFzHwM+ATl5iLtujkz52Tm/1KG1riqTr+D\ncgerAb+sP68CXh0Rq1EGXDuxngl8nTImzVIt8w32SuCelrONSyk77NFwdWb217rvyczb6vM76+fY\ngnJkf0mtdxpl6IUrgRdHxJmU0S9PaBngccAMYJf6vouA5eqyAK7MzIfruq6i3JvgfMrY/qdQxr/5\n7ih9RnU5m4nUNbLcQnH/iNilZfLg8VKWaXk8uFO49XnrUL5Ptkzrp4zr8thQ7fb1xOTxIcobXEfP\nENOeqSeGeTywnscoY0QdOPiNUW55OJVyF63rI+INg2Z5DPi/9Qym9X17s/DBYA/Qn5m31M7vzSmD\noh1EGShNSzjPDNRtDqLczm/Z+vxBylEw9Yj+1c9gmQN3q9oMuCkz5wF/jYi31OW+MiI+u4hl3Aqs\nFhFr1udbUfopOuFKyk2IVgSIiAMiYmpEbA1sn5lXZuYnKc1Eq1HCb+n63isofQ1ExFIRcWw8dROj\nTSJi+YjooWyb30XEO4GN6mBnBwBr1hE8tYQzDNRV6u0Az+Kp8dx/AUyMiGsonatDNeGMZAGlaegC\nyg3ID6/T9wIOiYjLgFN5qilpuLoepdy39oyBy0Ipnb+Ny8zrKf0dl9YRK7egDIedwH9ExOW1pl9k\n5u2UEVH3iYgj6/seqqN2XkPpV5lTF/17ylj/1/LUsM5/pNzb+FfAJcCXm7wsV93DUUul56DBV2lJ\nnhlIkjwzkCR5ZiBJwjCQJGEYSJIwDCRJGAaSJOD/Az/8icJ4qy1hAAAAAElFTkSuQmCC\n","text/plain":["<matplotlib.figure.Figure at 0x7f785afaa160>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"8NnO6FSyi6To","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","'''\n","This is used to store all the frames which we will be using to save our animation file\n","'''\n","frames=[]\n","'''\n","Before we proceed we reset the environment to bring it to initial state\n","'''\n","obs = env.reset()\n","for i in range(1000):\n","    '''\n","    model.predict-> It gets the model’s action from an observation\n","    '''\n","    action, _states = model.predict(obs)\n","    '''\n","    Step function makes a step from the current state to next.\n","    The step function returns 4 values namely observation,reward,done and info\n","    \n","    observation -> Represents agent's observation of the environment\n","    reward -> amount of reward achieved by the previous action\n","    done -> If the game is over\n","    info -> some kind of information which can be used for debugging\n","    '''\n","    obs, rewards, dones, info = env.step(action)\n","    screen = env.render(mode='rgb_array')\n","    #This appending lets us create an animation later\n","    frames.append(screen)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"rrknYbtEjQlU","colab_type":"code","outputId":"a898d5be-412b-4c5f-e77b-860a2a0f79f5","executionInfo":{"status":"ok","timestamp":1544067394388,"user_tz":300,"elapsed":400135,"user":{"displayName":"Vishnu Varshath Harishankar","photoUrl":"","userId":"00335552339456143148"}},"colab":{"base_uri":"https://localhost:8080/","height":269}},"cell_type":"code","source":["#Combine all frames into an animation \n","fig, ax = plt.subplots()\n","plt.axis('off')\n","l = ax.imshow(frames[0])\n","\n","def animate(i):\n","    l.set_data(frames[i])\n","\n","Writer = animation.writers['ffmpeg']\n","writer = Writer(fps=12, metadata=dict(artist='Me'))\n","ani = animation.FuncAnimation(fig, animate, frames=len(frames))\n","\n","ani.save('bonus2.mp4', writer=writer, dpi=220)\n","time.sleep(5) # let it process (only necessary in Colab)"],"execution_count":11,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAMsAAAD8CAYAAADZhFAmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAA+FJREFUeJzt3DFqHFcAgOEZoz64NKkManKDnEBI\nrUEhTVz5AGlSpUnjLkUO4EqBYCJIG6ET5AABNwY3TmKcxBHGZWBcSY1W0R+05q3Y72t2mQfvTfPz\ndnZ2dl6WZQKud2f0CcBtIRaIxAKRWCASC0RigUgsEIkFIrFAtDNy8Xme/XyAjbMsy7zquJ0FIrFA\nJBaIxAKRWCASC0RDvzpms7z4+fDSsfsHxwPOZDPZWbjk/sGxSFYQC0RigUgsEIkFIrFAJBaIxAKR\nm5JcsurmJNM0j/z7Vg9/sYk8/AU3JBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgs\nEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCAS\nC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaI\nxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkF\nIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0Ri\ngUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKR\nWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFA\nJBaIxAKRWCASC0RigUgsEIkFIrFAJBaIxAKRWCASC0RigUgsEIkFIrFAJJYt9Ou3/44+hVtJLBCJ\nZQu9PP1hmqZpOtk7mk72jgafze0hFojEApFYIBLLlll1jeK6pRELRGLZIv+1g9hdricWiMSyhfZP\nH168nr/nemKBSCwQiQWieVmWcYvP87jF4QrLssyrjttZINoZufhX35ytba6vp++mx9OXH2wchsZy\n9s+79U1295r5bjrOFvlo5dGh1yyHXzxby+JPdn+8eP/o+WdrH2e7HH//ycprlqE7y5u/3q5not1p\nevDL/vTTpyer57zpOEyDY/nz9fquWc7numrOm47D0I9h9z5+6qtjNs4fv32+eR/DXv3+98jl4X9x\nnwUisUAkFojEApFYIBILRGKBSCwQiQUisUAkFojEApFYIBILRGKBSCwQDX1SEm4TOwtEYoFILBCJ\nBSKxQCQWiMQCkVggEgtEYoFILBCJBSKxQCQWiMQCkVggEgtEYoFILBCJBSKxQCQWiMQC0Xv8KYiz\nrW7Z8wAAAABJRU5ErkJggg==\n","text/plain":["<matplotlib.figure.Figure at 0x7f7851c16ac8>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"VvT2R4rPjNrh","colab_type":"code","colab":{}},"cell_type":"code","source":["# To Save Animation\n","files.download('bonus2.mp4')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NIJXyXlKJF58","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}